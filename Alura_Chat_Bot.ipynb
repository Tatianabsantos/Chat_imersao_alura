{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3DHWawWu3ddRFe1ZvVUOL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tatianabsantos/Chat_imersao_alura/blob/main/Alura_Chat_Bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalando o SDK do google\n",
        "\n",
        "instalação !pip, o pip é gestor de pacotes do python\n",
        "como este comando gera muitos outpouts vamos utilizar o - q para ter um resultado silencioso, saida do output e vamos usar o - u caso eu já tenha uma versa instalidade, ele vai fazer o updat automaticamente"
      ],
      "metadata": {
        "id": "uO1CVUeeUzgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "4N4vABnBQKR2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Configurar a API Key\n",
        "\n",
        "\n",
        "import google.generativeai as genai #vai importar o que acabamos de isntalar google-generativeai para ser usadoo AS serve para dar um apleido para biblioteca\n",
        "from google.colab import userdata\n",
        "api_key= userdata.get('SECREAT_KEY')\n",
        "\n",
        "GOOGLE_API_KEY= api_key # informe sua API, como é tetxo precisa estar entre aspas, neste caso, como vou publicar o codigo estou usando uma chave secreta, mas o espaçopode ser preenchido pelo enderço da chave\n",
        "genai.configure(api_key=GOOGLE_API_KEY) #esta linha configura a API no meu projeto, ou seja estou criando um cliente do geminie para ser utilizado daqui pra frente\n"
      ],
      "metadata": {
        "id": "HgHjjnMHQYUW"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Listar os modelos disponíveis"
      ],
      "metadata": {
        "id": "KyI_0_j4V3Pl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models(): # esta linha contem um for que esta solicitando a lista de modelos dispoveis. O 'm' pode qualuqer letra, aqui ele representa m de modelo\n",
        "  if 'generateContent' in m.supported_generation_methods: # esta linha de codigo veririfca se os modelos da google tem o campo generate_contntent(se são modelos que geram conteudo), ou seja, veirifique lá no genai.list_models se ele tiver este campo generateContent de geraçao de conteudo me mostre quais são.\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "CoEc9lFhWBv8",
        "outputId": "75199018-9b44-497e-d0f6-6b6eaaf5d50e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proximo Passo é criar um dicionario de opções, para testas as variáveis, como temperatura, top k, top p.\n",
        "generate_config é somente um nome de variável, poderia ser outr nome\n",
        "*{} os colchetes são necessário para criar várias opções com dicionários\n",
        "*candidate_count é para retornar apenas 1 resposta ou alterantiva, o modelo pode dar várias, mas só vai retornar uma opção.\n",
        "*Temperature - 0.5, quanto maior mais criativo, quanto menor será fiel a repsosta, vamos colocar meio termo.\n",
        "*safety_settings - são os parametros de segunraç, também é só um nome de variavel\n"
      ],
      "metadata": {
        "id": "Nd5R81raF4H2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = {\n",
        "    'candidate_count': 1,\n",
        "    'temperature': 0.5,\n",
        "}"
      ],
      "metadata": {
        "id": "h6-qFupSFtyO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#aqui estamos criando e organizando varaveis para colocar dentro do modelo. Nesse caso são as vavoaveis de seguranças contidas no Atudio IA do Google, na secção safety settings logo abaixo da temperatura\n",
        "safety_settings = {\n",
        "    'HARASSMENT':'BLOCK_NONE',\n",
        "    'HATE':'BLOCK_NONE',\n",
        "    'SEXUAL':'BLOCK_NONE',\n",
        "    'DANGEROUS':'BLOCK_NONE'\n",
        "}"
      ],
      "metadata": {
        "id": "xuw3xyvxHdm2"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicializando o modelo"
      ],
      "metadata": {
        "id": "pTvetf0RJS4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inicar o modelo generativo\n",
        "#aqui vamos escolher qual o modelo vamos utlizar da lista de modelos dispoveis encontradas pelo 'for' acima\n",
        "model = genai.GenerativeModel(model_name= 'gemini-1.0-pro',\n",
        "                              generation_config=generation_config,\n",
        "                              safety_settings=safety_settings)"
      ],
      "metadata": {
        "id": "cQiKdlIfTBT-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate text"
      ],
      "metadata": {
        "id": "CxSqUw5MMZc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Aqui vamos gerar o conteudo\n",
        "#response é a reposta\n",
        "response = model.generate_content('Vamos aprender muito conteudo sobre conteudo sobre IA. Me dê sugestões.')\n",
        "print(response.text) #será o texto da resposta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "id": "wGDJgKccTQeS",
        "outputId": "be54441c-7065-4d33-f6bd-d6039cee7a2f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Recursos Online**\n",
            "\n",
            "* **Coursera:** Cursos especializados em IA, aprendizado de máquina e visão computacional\n",
            "* **edX:** Cursos online gratuitos e pagos sobre IA e tópicos relacionados\n",
            "* **MIT OpenCourseWare:** Materiais de cursos do MIT sobre IA, incluindo algoritmos, teoria e aplicações\n",
            "* **Stanford Online:** Cursos sobre IA, aprendizado profundo e processamento de linguagem natural\n",
            "* **Kaggle:** Plataforma de aprendizado de máquina e ciência de dados com tutoriais, competições e conjuntos de dados\n",
            "\n",
            "**Livros**\n",
            "\n",
            "* **Artificial Intelligence: A Modern Approach (4ª edição)** por Stuart Russell e Peter Norvig\n",
            "* **Machine Learning Yearning** por Andrew Ng\n",
            "* **Deep Learning** por Ian Goodfellow, Yoshua Bengio e Aaron Courville\n",
            "* **Natural Language Processing with Deep Learning** por Steven Bird, Ewan Klein e Edward Loper\n",
            "* **Computer Vision: Algorithms and Applications (2ª edição)** por Richard Szeliski\n",
            "\n",
            "**Revistas e Publicações**\n",
            "\n",
            "* **Nature Machine Intelligence:** Publicação científica dedicada à IA\n",
            "* **IEEE Transactions on Artificial Intelligence:** Revista técnica sobre IA e seus avanços\n",
            "* **Artificial Intelligence:** Revista acadêmica sobre a teoria e prática da IA\n",
            "* **Journal of Machine Learning Research:** Publicação online de acesso aberto sobre aprendizado de máquina\n",
            "* **ACM Transactions on Intelligent Systems and Technology:** Revista da Association for Computing Machinery sobre sistemas inteligentes\n",
            "\n",
            "**Canais do YouTube**\n",
            "\n",
            "* **Lex Fridman:** Entrevistas com especialistas em IA, ciência e tecnologia\n",
            "* **DeepMind:** Canal oficial do laboratório de pesquisa de IA do Google\n",
            "* **3Blue1Brown:** Vídeos animados que explicam conceitos complexos de IA\n",
            "* **MIT Technology Review:** Notícias e análises sobre IA e outras tecnologias emergentes\n",
            "* **Two Minute Papers:** Resumos rápidos de artigos de pesquisa em IA\n",
            "\n",
            "**Eventos e Conferências**\n",
            "\n",
            "* **Conferência Internacional Conjunta sobre Inteligência Artificial (IJCAI)**\n",
            "* **Conferência sobre Sistemas de Processamento de Informação Neural (NeurIPS)**\n",
            "* **Conferência Internacional sobre Aprendizado de Máquina (ICML)**\n",
            "* **Conferência sobre Visão Computacional e Reconhecimento de Padrões (CVPR)**\n",
            "* **Conferência sobre Processamento de Linguagem Natural (ACL)**\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criando o Chat"
      ],
      "metadata": {
        "id": "ZRkhdcJtOBHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#aqui vamos criar uma variavel chamada chat\n",
        "chat = model.start_chat(history=[]) # vamos iniciar o chat usando a variavel history para que ele lembre do conteudo que estamos conversando e armazene em uma lista, que no inicio será vazia"
      ],
      "metadata": {
        "id": "fy9exv9_OC3X"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#quero algo interativo, fazer perguntas e obter repostas\n",
        "prompt = input('Esperando o prompt: ') # aqui estamos criando uma variavel chamada prompt para receber as perguntas atravez de um input\n",
        "\n",
        "while prompt != 'fim':\n",
        "  response = chat.send_message(prompt)\n",
        "  print('Resposta: ', response.text, '\\n')\n",
        "  prompt = input('Esperando o prompt: ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "yF9EymjTO60P",
        "outputId": "b7d5a1a6-284c-49bc-8434-42a7a2d32caa"
      },
      "execution_count": 34,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Esperando o prompt: O que é o Gemini da Google?\n",
            "Resposta:  **Gemini** é um modelo de linguagem de IA multimodal desenvolvido pelo Google. É treinado em um conjunto de dados massivo de texto e código, permitindo que ele:\n",
            "\n",
            "* **Entenda e gere linguagem natural:** Pode compreender o significado do texto, responder perguntas e gerar texto semelhante ao humano.\n",
            "* **Escreva diferentes tipos de conteúdo:** Pode criar vários tipos de conteúdo, como artigos, resumos, histórias e até mesmo código.\n",
            "* **Traduzir idiomas:** Pode traduzir texto entre mais de 100 idiomas.\n",
            "* **Responder perguntas complexas:** Pode fornecer respostas abrangentes e informativas para perguntas complexas.\n",
            "* **Auxiliar na programação:** Pode ajudar os desenvolvedores a escrever código, depurar erros e sugerir melhorias.\n",
            "\n",
            "O Gemini foi projetado para ser uma ferramenta versátil que pode auxiliar os usuários em uma ampla gama de tarefas relacionadas à linguagem e à programação. \n",
            "\n",
            "Esperando o prompt: Posso ler um arquivo em formato PDF, usando o Gemini?\n",
            "Resposta:  O Gemini, o modelo de linguagem de IA do Google, não possui a capacidade de ler arquivos PDF diretamente. No entanto, você pode usar o Gemini para realizar tarefas relacionadas a arquivos PDF, como:\n",
            "\n",
            "* **Extrair texto de PDFs:** Você pode usar o Gemini para extrair o texto de um arquivo PDF e convertê-lo em um formato legível por máquina.\n",
            "* **Resumir PDFs:** Você pode usar o Gemini para resumir o conteúdo de um arquivo PDF, fornecendo uma visão geral concisa de seus pontos principais.\n",
            "* **Traduzir PDFs:** Se o arquivo PDF estiver em um idioma diferente, você pode usar o Gemini para traduzi-lo para o idioma de sua preferência.\n",
            "* **Gerar conteúdo relacionado a PDFs:** Você pode usar o Gemini para gerar conteúdo relacionado ao conteúdo de um arquivo PDF, como perguntas frequentes, descrições de produtos ou postagens de blog.\n",
            "\n",
            "Para realizar essas tarefas, você pode usar a API do Gemini ou integrá-la ao seu aplicativo ou fluxo de trabalho. \n",
            "\n",
            "Esperando o prompt: fim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Melhorando a visuzalição do chat"
      ],
      "metadata": {
        "id": "_Mzow0uKRqUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown #formato mais bonito, colocar titulo, topicos, negrito\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('*', ' * ')\n",
        "  return Markdown(textwrap.indent(text, ' > ', predicate=lambda _: True))\n",
        "\n",
        "#Imprimindo o histórico\n",
        "for message in chat.history:\n",
        "  display(to_markdown(f'**{message.role}**: {message.parts[0].text}'))\n",
        "  print('--------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1OfPOPK-RuST",
        "outputId": "3bcef3a3-7419-4771-9588-0f58938a3b48"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " >  *  * user *  * : Qual a capital do Japão?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " >  *  * model *  * : Tóquio"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " >  *  * user *  * : Qual é acomida tipica desse país?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " >  *  * model *  * : Sushi"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " >  *  * user *  * : meu primo nasceu nessa cidade. Qual é a nascionalidade dele?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " >  *  * model *  * : Japonesa"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " >  *  * user *  * : e qual é a população dessa cidade?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " >  *  * model *  * : 13.960.236 (2023)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " >  *  * user *  * : O que é o Gemini?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " >  *  * model *  * :  *   *  * Constelação: *  *  Uma constelação no hemisfério norte, conhecida por suas estrelas gêmeas brilhantes, Castor e Pólux.\n > \n >  *   *  * Signo do Zodíaco: *  *  O terceiro signo do zodíaco, que abrange os nascidos entre 21 de maio e 21 de junho.\n > \n >  *   *  * Programa Espacial: *  *  Um programa espacial conjunto da NASA e da Agência Espacial Europeia (ESA) que lançou uma sonda para explorar o planeta Mercúrio.\n > \n >  *   *  * Observatório de Gêmeos: *  *  Um observatório astronômico localizado no Havaí e no Chile, que possui dois telescópios gêmeos de 8,1 metros.\n > \n >  *   *  * Projeto Gemini: *  *  Um programa espacial tripulado da NASA que lançou dez missões entre 1965 e 1966, preparando o caminho para as missões lunares Apollo.\n > \n >  *   *  * Avião: *  *  Um avião bimotor usado para treinamento e transporte militar.\n > \n >  *   *  * Satélite: *  *  Uma série de satélites de comunicação lançados pela SpaceX."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " >  *  * user *  * : O que é o Gemini da Google?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " >  *  * model *  * :  *  * Gemini *  *  é um modelo de linguagem de IA multimodal desenvolvido pelo Google. É treinado em um conjunto de dados massivo de texto e código, permitindo que ele:\n > \n >  *   *  * Entenda e gere linguagem natural: *  *  Pode compreender o significado do texto, responder perguntas e gerar texto semelhante ao humano.\n >  *   *  * Escreva diferentes tipos de conteúdo: *  *  Pode criar vários tipos de conteúdo, como artigos, resumos, histórias e até mesmo código.\n >  *   *  * Traduzir idiomas: *  *  Pode traduzir texto entre mais de 100 idiomas.\n >  *   *  * Responder perguntas complexas: *  *  Pode fornecer respostas abrangentes e informativas para perguntas complexas.\n >  *   *  * Auxiliar na programação: *  *  Pode ajudar os desenvolvedores a escrever código, depurar erros e sugerir melhorias.\n > \n > O Gemini foi projetado para ser uma ferramenta versátil que pode auxiliar os usuários em uma ampla gama de tarefas relacionadas à linguagem e à programação."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " >  *  * user *  * : Posso ler um arquivo em formato PDF, usando o Gemini?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " >  *  * model *  * : O Gemini, o modelo de linguagem de IA do Google, não possui a capacidade de ler arquivos PDF diretamente. No entanto, você pode usar o Gemini para realizar tarefas relacionadas a arquivos PDF, como:\n > \n >  *   *  * Extrair texto de PDFs: *  *  Você pode usar o Gemini para extrair o texto de um arquivo PDF e convertê-lo em um formato legível por máquina.\n >  *   *  * Resumir PDFs: *  *  Você pode usar o Gemini para resumir o conteúdo de um arquivo PDF, fornecendo uma visão geral concisa de seus pontos principais.\n >  *   *  * Traduzir PDFs: *  *  Se o arquivo PDF estiver em um idioma diferente, você pode usar o Gemini para traduzi-lo para o idioma de sua preferência.\n >  *   *  * Gerar conteúdo relacionado a PDFs: *  *  Você pode usar o Gemini para gerar conteúdo relacionado ao conteúdo de um arquivo PDF, como perguntas frequentes, descrições de produtos ou postagens de blog.\n > \n > Para realizar essas tarefas, você pode usar a API do Gemini ou integrá-la ao seu aplicativo ou fluxo de trabalho."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}